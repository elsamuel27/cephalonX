{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo y los datos de prueba\n",
    "modelo = tf.keras.models.load_model(\"assets/modelo.tf\")\n",
    "testData = pd.read_csv(\"./test.csv\", quotechar='\"')\n",
    "\n",
    "with open('./assets/tokenizer_config.txt', 'r', encoding='utf-8') as f:\n",
    "    tokenizer_config_loaded = f.read()\n",
    "    tokenizer_config_dict = eval(tokenizer_config_loaded)\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer.from_config(tokenizer_config_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le a√±adimos a la tabla una columna para las respuestas\n",
    "testData[\"respuestas\"] = \"\"\n",
    "for index, row in testData.iterrows():\n",
    "    respuesta = modelo.predict(row['preguntas']) # iteramos sobre las preguntas para pedirle cada una al modelo\n",
    "    testData.at[index, 'respuestas'] = respuesta # y obviamente las guardamos cada una en su fila correspondiente\n",
    "\n",
    "# Y queda exportar la nueva tabla\n",
    "testData.to_csv(quotechar='\"', lineterminator=\",\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

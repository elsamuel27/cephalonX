{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He plasmado todos los datos dentro de archivos CSV, que están en la carpeta [\"data\"](data/), por lo que ahora para cargarlos sólo hay que crear un DataFrame de Pandas vacío y juntar en él los datos de todos los archivos. Un bucle \"for\" nos hace el trabajo independientemente de cuántos archivos estén (Siempre y cuando todos tengan la misma estructura claro, pero estoy cuidando eso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "\n",
    "for archivo in os.listdir(\"./data\"):\n",
    "    if archivo.endswith(\".csv\"):\n",
    "        dataset = pd.concat([dataset, pd.read_csv(os.path.join(\"./data\", archivo), delimiter=\",\", quotechar='\"', header=None)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método para almacenar los datos funciona, pero ello no implica que un modelo pueda entenderlos. Deben ser tokenizados, para ello Keras lleva un tokenizador y nos sirve con los datos así como los he guardado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno no prepara los datos y comienza el entrenamiento ya, hay que hacer un par de cosas primero. Entre ellas, configurar un checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoints/model.tf\"\n",
    "    monitor=\"val_loss\"\n",
    "    mode=min\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Éste objeto de Keras se encarga de ir guardando el modelo en mitad del entrenamiento. Al no tener ninguna variable el nombre (aunque se le podrían poner), en la ruta sólo va a haber un modelo siempre, y gracias al resto de parámetros, siempre será el que haya sacado la pérdida de validación (val_loss) más baja"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
